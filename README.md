# WebGym
A port of OpenAI's Gym for the Internet!

The [OpenAI Gym](https://gym.openai.com/) is a very popular toolkit for developing, testing, and optimizing reinforcement learning models. Currently, only automated algorithms can interact with the gym, making organic human data collection quite difficult; this project is meant to remediate that, and provide a novel way to collect real-world data for RL model development.


## Getting Started

To get started, download the files and open in your code editor. Install the requirements; if you're using pip, then you can run the following command:

```console
foo@bar:~$ pip install -r requirements.txt
```

Run the Python `server.py` file. Once the program begins running, type in `localhost:8080` into your web browser. Have fun playing with the Gym! 

To change the environment (from say, [LunarLander](https://gym.openai.com/envs/LunarLander-v2/) to [Acrobot](https://gym.openai.com/envs/Acrobot-v1/)), simply change the name in `server.py`.

## Notes

You'll probably be interested in the keystrokes and corresponding reward values generated by human gameplay; this data currently prints in the terminal, and can be saved by sending the results of the server.py to some output file, as so:
```console
foo@bar:~$ python server.py > output.txt
```

## Permissions

This project is licensed under the MIT License - see the License for details.

## Author

Developed by Nikesh Mishra with the Intelligent and Interactive Autonomous Systems Group at the Stanford AI Lab. Funded by the 2020 Research Experience for Undergraduates (REU) program at the Stanford University Department of Electrical Engineering.
